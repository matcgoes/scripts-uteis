{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# No BS Guide to Hyperparameter Tuning With Optuna\n## Everyone is obsessed with it these days, let's find out why\n![](https://cdn-images-1.medium.com/max/1200/1*zvONsmZNnZHIlwjhJqgu5Q.jpeg)\n<figcaption style=\"text-align: center;\">\n    <strong>\n        Photo by \n        <a href='https://pixabay.com/users/bomei615-2623913/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1751855'>Bo Mei</a>\n        on \n        <a href='https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1751855'>Pixabay.</a> All images are by author unless specified otherwise.\n    </strong>\n</figcaption>","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport optuna\nimport pandas as pd\nimport seaborn as sns\n\noptuna.logging.set_verbosity(optuna.logging.WARNING)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:19.829980Z","iopub.execute_input":"2021-07-30T15:59:19.830640Z","iopub.status.idle":"2021-07-30T15:59:22.022589Z","shell.execute_reply.started":"2021-07-30T15:59:19.830534Z","shell.execute_reply":"2021-07-30T15:59:22.021699Z"},"_kg_hide-input":true,"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"Turns out I have been living under a rock.\n\nWhile every single MOOC taught me to use GridSearch for hyperparameter tuning, Kagglers have been using Optuna almost exclusively for almost 2 years. This even predates the time I started learning data science.\n\nKaggle community is known for its brutal competitiveness, and for a package to achieve this level of domination, it needs to be damn good. After being active on the platform for the last month (and achieving [expert status](https://medium.com/r/?url=https%3A%2F%2Fwww.kaggle.com%2Fbextuychiev) in two tiers), I saw Optuna used almost everywhere and by everyone.\n\nSo, what makes Optuna so widely received by the largest machine learning community out there? We will answer this question in this kernel by getting hands-on on the framework. We will learn how it works and how it squeezes every bit of performance out of any model, including neural networks.","metadata":{}},{"cell_type":"markdown","source":"# What is Optuna?","metadata":{}},{"cell_type":"markdown","source":"![](https://raw.githubusercontent.com/optuna/optuna/master/docs/image/optuna-logo.png)\n<figcaption style=\"text-align: center;\">\n    <strong>\n        Optuna logo\n    </strong>\n</figcaption>","metadata":{}},{"cell_type":"markdown","source":"Optuna is a next-generation automatic hyperparameter tuning framework written completely in Python.\n\nIts most prominent features are:\n- the ability to define Pythonic search spaces using loops and conditionals.\n- Platform-agnostic API - you can tune estimators of almost any ML, DL package/framework, including Sklearn, PyTorch, TensorFlow, Keras, XGBoost, LightGBM, CatBoost, etc.\n- a large suite of optimization algorithms with early stopping and pruning features baked in.\n- Easy parallelization with little or no changes to the code.\n- Built-in support for visual exploration of search results.\n\nWe will try to validate these overly optimistic claims made in [Optuna's documentation](https://optuna.readthedocs.io/en/stable/index.html) in the coming sections.","metadata":{}},{"cell_type":"markdown","source":"# Optuna basics","metadata":{}},{"cell_type":"markdown","source":"Let's familiarize ourselves with Optuna API by tuning a simple function like $(x-1)^2 + (y+3)^2$. We know the function reaches its minimum at x=1 and y=-3. Let's see if Optuna can find these:","metadata":{}},{"cell_type":"code","source":"import optuna  # pip install optuna\n\n\ndef objective(trial):\n    x = trial.suggest_float(\"x\", -7, 7)\n    y = trial.suggest_float(\"y\", -7, 7)\n    return (x - 1) ** 2 + (y + 3) ** 2","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:22.024407Z","iopub.execute_input":"2021-07-30T15:59:22.024689Z","iopub.status.idle":"2021-07-30T15:59:22.031635Z","shell.execute_reply.started":"2021-07-30T15:59:22.024663Z","shell.execute_reply":"2021-07-30T15:59:22.030474Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"After importing `optuna`, we define an objective that returns the function we want to minimize.\n\nIn the body of the objective, we define the parameters to be optimized, in this case, simple `x` and `y`. The argument `trial` is a special `Trial` object of optuna, which does the optimization for each hyperparameter.\n\nAmong others, it has a `suggest_float` method that takes the name of the hyperparameter and the range to look for its optimal value. In other words,\n\n```\nx = trial.suggest_float(\"x\", -7, 7)\n```\nis almost the same as `{\"x\": np.arange(-7, 7)}` when doing GridSearch.\n\nTo start the optimization, we create a `study` object from Optuna and pass the `objective` function to its `optimize` method:","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study()\nstudy.optimize(objective, n_trials=100)  # number of iterations","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:22.034325Z","iopub.execute_input":"2021-07-30T15:59:22.034835Z","iopub.status.idle":"2021-07-30T15:59:22.773826Z","shell.execute_reply.started":"2021-07-30T15:59:22.034771Z","shell.execute_reply":"2021-07-30T15:59:22.773072Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:22.775104Z","iopub.execute_input":"2021-07-30T15:59:22.775551Z","iopub.status.idle":"2021-07-30T15:59:22.783245Z","shell.execute_reply.started":"2021-07-30T15:59:22.775520Z","shell.execute_reply":"2021-07-30T15:59:22.782228Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'x': 1.0705677116765648, 'y': -2.7576827578838046}"},"metadata":{}}]},{"cell_type":"markdown","source":"Pretty close, but not as close as you would want. Here, we only did 100 trials, as can be seen with:","metadata":{}},{"cell_type":"code","source":"len(study.trials)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:22.784442Z","iopub.execute_input":"2021-07-30T15:59:22.784743Z","iopub.status.idle":"2021-07-30T15:59:22.811900Z","shell.execute_reply.started":"2021-07-30T15:59:22.784708Z","shell.execute_reply":"2021-07-30T15:59:22.810978Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"100"},"metadata":{}}]},{"cell_type":"markdown","source":"Now, I will introduce the first magic that comes with Optuna. We can resume the optimization even after it is finished if we are not satisfied with the results!\n\nThis is a **distinct advantage** over other similar tools because after the search is done, they completely forget the history of previous trials. Optuna does not!\n\nTo continue searching, call `optimize` again with the desired params. Here, we will run 100 more trials:","metadata":{}},{"cell_type":"code","source":"study.optimize(objective, n_trials=100)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:22.813084Z","iopub.execute_input":"2021-07-30T15:59:22.813577Z","iopub.status.idle":"2021-07-30T15:59:23.739200Z","shell.execute_reply.started":"2021-07-30T15:59:22.813547Z","shell.execute_reply":"2021-07-30T15:59:23.738496Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"study.best_params","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:23.740364Z","iopub.execute_input":"2021-07-30T15:59:23.740869Z","iopub.status.idle":"2021-07-30T15:59:23.746315Z","shell.execute_reply.started":"2021-07-30T15:59:23.740836Z","shell.execute_reply":"2021-07-30T15:59:23.745277Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'x': 0.966179630630595, 'y': -3.029255218531449}"},"metadata":{}}]},{"cell_type":"markdown","source":"This time, the results are much closer to the optimal parameters.","metadata":{}},{"cell_type":"markdown","source":"# A note on Optuna terminology and conventions","metadata":{}},{"cell_type":"markdown","source":"In Optuna, the whole optimization process is called a study. For example, tuning XGBoost parameters with a log loss as a metric is one study:","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study()\ntype(study)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:23.749262Z","iopub.execute_input":"2021-07-30T15:59:23.749643Z","iopub.status.idle":"2021-07-30T15:59:23.766140Z","shell.execute_reply.started":"2021-07-30T15:59:23.749604Z","shell.execute_reply":"2021-07-30T15:59:23.764817Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"optuna.study.Study"},"metadata":{}}]},{"cell_type":"markdown","source":"A study needs a function it can optimize. Typically, this function is defined by the user, and by convention, it should be named `objective`.\n\nThe objective function is expected to have this signature:","metadata":{}},{"cell_type":"code","source":"def objective(trial: optuna.Trial):\n    \"\"\"Conventional optimization function\n    signature for optuna.\n    \"\"\"\n    custom_metric = ...\n    return custom_metric","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:23.768244Z","iopub.execute_input":"2021-07-30T15:59:23.768580Z","iopub.status.idle":"2021-07-30T15:59:23.777985Z","shell.execute_reply.started":"2021-07-30T15:59:23.768549Z","shell.execute_reply":"2021-07-30T15:59:23.776768Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"It should accept an `optuna.Trial` object as a parameter and return the metric we want to optimize for.\n\nAs we saw in the first example, a study is a collection of trials wherein each trial, we evaluate the objective function using a single set of hyperparameters from the given search space.\n\nEach trial in the study is represented as `optuna.Trial` class. This class is key to how Optuna finds optimal values for parameters.\n\nTo start a study, we create a study object with `direction`:","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:23.779500Z","iopub.execute_input":"2021-07-30T15:59:23.779845Z","iopub.status.idle":"2021-07-30T15:59:23.793547Z","shell.execute_reply.started":"2021-07-30T15:59:23.779805Z","shell.execute_reply":"2021-07-30T15:59:23.792104Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"If the metric we want to optimize is a point-performance score like ROC AUC or accuracy, we set the direction to `maximize`. Otherwise, we minimize a loss function like RMSE, RMSLE, log loss, etc. by setting direction to `minimize`.\n\nThen, we will call the optimize method of the study passing the objective function name and the number of trials we want:\n\n```python\n# Optimization with 100 trials\nstudy.optimize(objective, n_trials=100)\n```\n\nNext, we will take a closer look into creating these objective functions.","metadata":{}},{"cell_type":"markdown","source":"# Defining the search space","metadata":{}},{"cell_type":"markdown","source":"Usually, the first thing you do in an objective function is to create the search space using built-in Optuna methods:","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    rf_params = {\n        \"n_estimators\": trial.suggest_integer(name=\"n_estimators\", low=100, high=2000),\n        \"max_depth\": trial.suggest_float(\"max_depth\", 3, 8),\n        \"max_features\": trial.suggest_categorical(\n            \"max_features\", choices=[\"auto\", \"sqrt\", \"log2\"]\n        ),\n        \"n_jobs\": -1,\n        \"random_state\": 1121218,\n    }\n\n    rf = RandomForestRegressor(**rf_params)\n    ...","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:23.795501Z","iopub.execute_input":"2021-07-30T15:59:23.795889Z","iopub.status.idle":"2021-07-30T15:59:23.806508Z","shell.execute_reply.started":"2021-07-30T15:59:23.795854Z","shell.execute_reply":"2021-07-30T15:59:23.805266Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"In the above objective function, we are creating a small search space of Random Forest hyperparameters.\n\nThe search space is a plain-old dictionary. To create possible values to search over, you must use the trial object's `suggest_*` functions.\n\nThese functions require at least the hyperparameter name, min, and max of the range to search over or possible categories for categorical hyperparameters.\n\nTo make the space smaller, `suggest_float` and `suggest_int` have additional `step` or `log` arguments:","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\n\ndef objective(trial):\n    params = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 10000, step=200),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-7, 0.3, log=True),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12, step=2),\n        \"random_state\": 1121218,\n    }\n    boost_reg = GradientBoostingRegressor(**params)\n    rmsle = ...\n    return rmsle","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:23.807715Z","iopub.execute_input":"2021-07-30T15:59:23.808123Z","iopub.status.idle":"2021-07-30T15:59:23.822321Z","shell.execute_reply.started":"2021-07-30T15:59:23.808088Z","shell.execute_reply":"2021-07-30T15:59:23.821328Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Above, we are binning the distribution of `n_estimators` by 200-intervals to make it sparser. Also, `learning_rate` is defined at a logarithmic scale.","metadata":{}},{"cell_type":"markdown","source":"# How are possible parameters sampled?","metadata":{}},{"cell_type":"markdown","source":"Under the hood, Optuna has several classes responsible for parameter sampling. These are:\n- `GridSampler`: the same as `GridSearch` of Sklearn. Never use for large search spaces!\n- `RandomSampler`: the same as `RandomizedGridSearch` of Sklearn.\n- `TPESampler`: Tree-structured Parzen Estimator sampler - bayesian optimization using kernel fitting\n- `CmaEsSampler`: a sampler based on CMA ES algorithm (does not allow categorical hyperparameters).\n\n> I have no idea of how the last two samplers work and I don't expect this to affect any interaction I have with Optuna.\n\nTPE Sampler is used by default - it tries to sample hyperparameter candidates by improving on the last trial's scores. In other words, you can expect incremental (maybe marginal) improvements from trial to trial with this sampler.\n\nIf you ever want to switch samplers, this is how you do it:","metadata":{}},{"cell_type":"code","source":"from optuna.samplers import CmaEsSampler, RandomSampler\n\n# Study with a random sampler\nstudy = optuna.create_study(sampler=RandomSampler(seed=1121218))\n\n# Study with a CMA ES sampler\nstudy = optuna.create_study(sampler=CmaEsSampler(seed=1121218))","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:23.823583Z","iopub.execute_input":"2021-07-30T15:59:23.824094Z","iopub.status.idle":"2021-07-30T15:59:23.837918Z","shell.execute_reply.started":"2021-07-30T15:59:23.824057Z","shell.execute_reply":"2021-07-30T15:59:23.836990Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# End-to-end example with GradientBoostingRegressor","metadata":{}},{"cell_type":"markdown","source":"Let's put everything we have learned into something tangible. We will be predicting penguin body weights using several numeric and categorical features.\n\nWe will establish a base score with Sklearn `GradientBoostingRegressor` and improve it by tuning with Optuna:","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import KFold, cross_validate, train_test_split\n\n# Load data\npenguins = sns.load_dataset(\"penguins\").dropna()\nX, y = penguins.drop(\"body_mass_g\", axis=1), penguins[[\"body_mass_g\"]]\n\n# OH encode categoricals\nX = pd.get_dummies(X)\n\n# Init model with defaults\ngr_reg = GradientBoostingRegressor(random_state=1121218)\n\nkf = KFold(n_splits=5, shuffle=True, random_state=1121218)\nscores = cross_validate(\n    gr_reg, X, y, cv=kf, scoring=\"neg_mean_squared_log_error\", n_jobs=-1\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:23.839119Z","iopub.execute_input":"2021-07-30T15:59:23.839585Z","iopub.status.idle":"2021-07-30T15:59:27.328877Z","shell.execute_reply.started":"2021-07-30T15:59:23.839551Z","shell.execute_reply":"2021-07-30T15:59:27.327550Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"rmsle = np.sqrt(-scores[\"test_score\"].mean())\nprint(f\"Base RMSLE: {rmsle:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:27.334277Z","iopub.execute_input":"2021-07-30T15:59:27.334701Z","iopub.status.idle":"2021-07-30T15:59:27.342112Z","shell.execute_reply.started":"2021-07-30T15:59:27.334662Z","shell.execute_reply":"2021-07-30T15:59:27.340924Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Base RMSLE: 0.07573\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now, we will create the `objective` function and define the search space:","metadata":{}},{"cell_type":"code","source":"def objective(trial, X, y, cv, scoring):\n    params = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 5000, step=100),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.3, log=True),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 0.9, step=0.1),\n        \"max_features\": trial.suggest_categorical(\n            \"max_features\", [\"auto\", \"sqrt\", \"log2\"]\n        ),\n        \"random_state\": 1121218,\n        \"n_iter_no_change\": 50,  # early stopping\n        \"validation_fraction\": 0.05,\n    }\n    # Perform CV\n    gr_reg = GradientBoostingRegressor(**params)\n    scores = cross_validate(gr_reg, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n    # Compute RMSLE\n    rmsle = np.sqrt(-scores[\"test_score\"].mean())\n\n    return rmsle","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:27.344208Z","iopub.execute_input":"2021-07-30T15:59:27.344948Z","iopub.status.idle":"2021-07-30T15:59:27.355944Z","shell.execute_reply.started":"2021-07-30T15:59:27.344897Z","shell.execute_reply":"2021-07-30T15:59:27.355015Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"We built a grid of 5 hyperparameters with different ranges and some static ones for random seed and early stopping.\n\nThe above objective function is slightly different - it accepts additional arguments for the data sets, scoring and `cv`. That's why we have to wrap it inside another function. Generally, you do this with a `lambda` function like below:\n\n> This is the recommended syntax if you want to pass `objective` functions that accept multiple parameters.","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Create study that minimizes\nstudy = optuna.create_study(direction=\"minimize\")\n\n# Wrap the objective inside a lambda with the relevant arguments\nkf = KFold(n_splits=5, shuffle=True, random_state=1121218)\n# Pass additional arguments inside another function\nfunc = lambda trial: objective(trial, X, y, cv=kf, scoring=\"neg_mean_squared_log_error\")\n\n# Start optimizing with 100 trials\nstudy.optimize(func, n_trials=100)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T15:59:27.357769Z","iopub.execute_input":"2021-07-30T15:59:27.358590Z","iopub.status.idle":"2021-07-30T16:01:42.639768Z","shell.execute_reply.started":"2021-07-30T15:59:27.358540Z","shell.execute_reply":"2021-07-30T16:01:42.638545Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"CPU times: user 4.55 s, sys: 138 ms, total: 4.69 s\nWall time: 2min 15s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Base RMSLE     : {rmsle:.5f}\")\nprint(f\"Optimized RMSLE: {study.best_value:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-30T16:01:42.641259Z","iopub.execute_input":"2021-07-30T16:01:42.641709Z","iopub.status.idle":"2021-07-30T16:01:42.648677Z","shell.execute_reply.started":"2021-07-30T16:01:42.641671Z","shell.execute_reply":"2021-07-30T16:01:42.647316Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Base RMSLE     : 0.07573\nOptimized RMSLE: 0.07238\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In just under a minute, we achieved a significant score boost (in terms of log errors, 0.004 is pretty sweet). We did this with only 100 trials. Let's boldly run another 200 and see what happens:","metadata":{}},{"cell_type":"markdown","source":"> The score was higher on my local machine. Forgot to seed the `study`, rookie mistake.","metadata":{}},{"cell_type":"code","source":"%%time\n\nstudy.optimize(func, n_trials=200)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T16:01:42.650588Z","iopub.execute_input":"2021-07-30T16:01:42.651062Z","iopub.status.idle":"2021-07-30T16:04:30.017952Z","shell.execute_reply.started":"2021-07-30T16:01:42.651015Z","shell.execute_reply":"2021-07-30T16:04:30.016565Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"CPU times: user 10.6 s, sys: 275 ms, total: 10.9 s\nWall time: 2min 47s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Best params:\")\nfor key, value in study.best_params.items():\n    print(f\"\\t{key}: {value}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-30T16:04:30.019805Z","iopub.execute_input":"2021-07-30T16:04:30.020230Z","iopub.status.idle":"2021-07-30T16:04:30.034198Z","shell.execute_reply.started":"2021-07-30T16:04:30.020188Z","shell.execute_reply":"2021-07-30T16:04:30.032628Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Best params:\n\tn_estimators: 2700\n\tlearning_rate: 0.007540191173067588\n\tmax_depth: 3\n\tsubsample: 0.5\n\tmax_features: sqrt\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Base RMSLE     : {rmsle:.5f}\")\nprint(f\"Optimized RMSLE: {study.best_value:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-30T16:04:30.036453Z","iopub.execute_input":"2021-07-30T16:04:30.036929Z","iopub.status.idle":"2021-07-30T16:04:30.049405Z","shell.execute_reply.started":"2021-07-30T16:04:30.036880Z","shell.execute_reply":"2021-07-30T16:04:30.048264Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Base RMSLE     : 0.07573\nOptimized RMSLE: 0.07233\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> All these didn't take that much long on my local machine. Sorry for people running this notebook...","metadata":{}},{"cell_type":"markdown","source":"The score *did* improve but marginally. It looks like we hit it close to the max in the first run!\n\nMost importantly, we achieved this score in just over 2 minutes using a search space that would probably take hours with regular GridSearch.\n\nI don't know about you, but I am sold!","metadata":{}},{"cell_type":"markdown","source":"# Using visuals for more insights and smarter tuning","metadata":{}},{"cell_type":"markdown","source":"Optuna offers a wide range of plots under its `visualization` subpackage. Here, we will discuss only 2, which I think are the most useful.\n\nFirst, let's plot the optimization history of the last `study`:","metadata":{}},{"cell_type":"code","source":"from optuna.visualization import plot_optimization_history\n\nplotly_config = {\"staticPlot\": True}\n\nfig = plot_optimization_history(study)\nfig.show(config=plotly_config)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T16:04:30.051719Z","iopub.execute_input":"2021-07-30T16:04:30.052142Z","iopub.status.idle":"2021-07-30T16:04:30.333704Z","shell.execute_reply.started":"2021-07-30T16:04:30.052101Z","shell.execute_reply":"2021-07-30T16:04:30.332736Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"8582ec03-c008-451d-bcc4-011cd2e6ba5d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8582ec03-c008-451d-bcc4-011cd2e6ba5d\")) {                    Plotly.newPlot(                        \"8582ec03-c008-451d-bcc4-011cd2e6ba5d\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"type\":\"scatter\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299],\"y\":[0.08146303198196324,0.08181270714194272,0.08658262460338328,0.07904479723432337,0.08008825065725879,0.07443561068756076,0.08632713603376181,0.14513852761951176,0.08183400666369023,0.0902754386098974,0.07496091918936439,0.07728360933800267,0.07454645982167198,0.0765322608888761,0.07444916397213107,0.07808814244322924,0.07400781988460552,0.07390114886880257,0.0752213471590272,0.07350049693335997,0.14948824645179543,0.07355717748990827,0.07362086569558983,0.07531334061442851,0.08614972136766082,0.07563399575708502,0.10665818039818122,0.07704280835664493,0.07405783632842984,0.07657654249077252,0.08893443584301984,0.07414175735131402,0.07360103036479998,0.07267954421999769,0.07275797470449033,0.07263173028599355,0.07263025556945062,0.07279663813785092,0.07410777183505154,0.07272793393722195,0.08352329066605746,0.07264229922072822,0.07321705200620296,0.07299470487469563,0.07349547682691025,0.07295400491588183,0.07283940604368065,0.07323010764562862,0.07897867601078781,0.07308077919667844,0.07288633216678443,0.07288557220339632,0.0727545328887076,0.07285098639507868,0.07332479738053188,0.07304510305436993,0.07346468950665618,0.07357008890958787,0.07384115660178953,0.07485670034844381,0.07395538072224188,0.07254916041035026,0.07245894501547102,0.07326456260089936,0.07246483005810284,0.073858886212557,0.07299976897384919,0.07427309020763957,0.07336883924757104,0.07298685638195947,0.07399360653824982,0.07302993128228497,0.07306154630162377,0.07258135620676184,0.07343289953135601,0.07257481636480084,0.07360326305454062,0.07306026841732692,0.07387438621782703,0.07361261317119511,0.07480385734726253,0.07304191630174839,0.07313638898609366,0.0729005864417307,0.07305949281718115,0.07322088421721286,0.07982244729692918,0.07387369302409987,0.07238286983554476,0.07319300560041608,0.0727291806483578,0.07315483625947267,0.07263415437580298,0.0731359125884247,0.0727082003262754,0.07253242852417244,0.07325396607701833,0.0732616303835448,0.07802331694654908,0.07377966522335942,0.07242828145768031,0.07277192672756225,0.07271780007280144,0.07285960887139088,0.07240314092594125,0.07304842307179932,0.07277415219983419,0.07281418473524003,0.07280142543388692,0.07696629619740616,0.07278035622365733,0.07306444529403382,0.07267628271132008,0.0723938615853099,0.07283088628608869,0.07257132049537952,0.07308251008915473,0.07262680763458838,0.07328711042033068,0.07248071881868352,0.073910527988716,0.0724896889945726,0.07255773011357178,0.0728023643290384,0.07307937079558709,0.07268303148577673,0.07304555121490361,0.07254769278205025,0.07284022315363263,0.07898700129333515,0.0723956164363567,0.07275812121911666,0.07286985866006586,0.07302931468170072,0.07287852200795275,0.09147970787850113,0.07306774701048915,0.0727049322589355,0.07292649426597819,0.0748255131661797,0.0784796622802169,0.07276898761571486,0.07287972085922473,0.07278954032268677,0.07284604410782694,0.07278552104316623,0.07258193332427182,0.07305968773467927,0.0778980570662932,0.07280606955476787,0.0731682031029392,0.07285263749004846,0.07265924845442868,0.07270435739609911,0.07547832139017274,0.07280609958905994,0.07269281417175598,0.07293951524546098,0.07294105308239514,0.07268132489376009,0.07254894503224806,0.07242883333158467,0.0729894666933256,0.0727062611004366,0.07256516371898467,0.07287107526615645,0.07315854573946357,0.07277817926922647,0.07315794769655548,0.07297208069264602,0.07250352307120095,0.0723536656777826,0.07286401170244791,0.07251535763221895,0.07255400805788258,0.07299860159241352,0.07318178123966232,0.07271524358629,0.07422821825197051,0.07277544475089581,0.07249472366040259,0.07248638322257299,0.07288520985891664,0.07278996545593074,0.07309183167069949,0.1484393210181285,0.07299092096530635,0.07258515171545803,0.07278054072172574,0.07327425864505864,0.07266997222118524,0.07298335444686786,0.07282306109894679,0.07262030114856018,0.07243002014119398,0.0730097394065604,0.07250861629770852,0.0724345900523763,0.0729980207161646,0.07249717472459631,0.07244785958634262,0.07268083581680883,0.07237693600451393,0.07289432580273617,0.07293288600972957,0.07299343739890528,0.07322042204095575,0.0728122128597957,0.07248803699298094,0.07334164841266377,0.0731825161629726,0.07279418438263205,0.07283528057507581,0.07237966093721829,0.07331327179441878,0.07321199983134451,0.07283065917639087,0.07307270553608655,0.07251560499975186,0.0728262711196743,0.07323324751468273,0.07324904628293027,0.07317256206577678,0.07291510070905116,0.07266630423594006,0.07285564489569275,0.0725783859640458,0.07331015005940583,0.07294116676462184,0.07495567717496751,0.07289973813965706,0.07288642391405972,0.07244321131778486,0.07325807322604663,0.0728045921696287,0.07307118867311944,0.07254090960029126,0.07290982395586423,0.0725362977390873,0.07264445402276744,0.07308862527187046,0.07302119615064294,0.07284985749041845,0.07305660125324415,0.0727916781149745,0.07252571537608964,0.07327267250718908,0.07307209762007562,0.07233392274627042,0.07511646467544342,0.07269705828966197,0.07256924649678584,0.0728689495383517,0.07261044978910781,0.07276608254382477,0.07254802297729139,0.07301945529776704,0.07367117905096113,0.07279390165742443,0.07294651321682266,0.07808766864509603,0.07301896004699629,0.07282376162053153,0.07241038837213544,0.0727514884537439,0.07284918779670292,0.07261637016455863,0.07275807465858045,0.0724582719268834,0.07338193217495612,0.07244899684375276,0.07258655772942896,0.07488725154100635,0.07294990888568628,0.07286158384289178,0.07325982690010602,0.07290686088134497,0.07277664244659254,0.07293464108190709,0.07322145646836425,0.0725561599626874,0.07285640207032483,0.07238506570239989,0.07295106796530308,0.0728460903359027,0.07252603147794418,0.07304938158587158,0.07244335699016202,0.0730252389491782,0.07239725988136608,0.07314889115701022,0.07968567897384347,0.07426144467688933,0.07241766745606495,0.07301488641090988,0.07289008331504475,0.07289770055778462,0.07297253216409058,0.07292680113714481,0.07328831998538185]},{\"name\":\"Best Value\",\"type\":\"scatter\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299],\"y\":[0.08146303198196324,0.08146303198196324,0.08146303198196324,0.07904479723432337,0.07904479723432337,0.07443561068756076,0.07443561068756076,0.07443561068756076,0.07443561068756076,0.07443561068756076,0.07443561068756076,0.07443561068756076,0.07443561068756076,0.07443561068756076,0.07443561068756076,0.07443561068756076,0.07400781988460552,0.07390114886880257,0.07390114886880257,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07350049693335997,0.07267954421999769,0.07267954421999769,0.07263173028599355,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07263025556945062,0.07254916041035026,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07245894501547102,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.07238286983554476,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.0723536656777826,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042,0.07233392274627042]}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"#Trials\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}}},                        {\"staticPlot\": true, \"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('8582ec03-c008-451d-bcc4-011cd2e6ba5d');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"markdown","source":"This plot tells us that Optuna made the score converge to the minimum after only a few trials.\n\nNext, let's plot hyperparameter importances:","metadata":{}},{"cell_type":"code","source":"from optuna.visualization import plot_param_importances\n\nfig = plot_param_importances(study)\nfig.show(config=plotly_config)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T16:04:30.336456Z","iopub.execute_input":"2021-07-30T16:04:30.336806Z","iopub.status.idle":"2021-07-30T16:04:45.883340Z","shell.execute_reply.started":"2021-07-30T16:04:30.336755Z","shell.execute_reply":"2021-07-30T16:04:45.882366Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"bd0b25ae-db20-4a67-876d-1ada92e3ace9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bd0b25ae-db20-4a67-876d-1ada92e3ace9\")) {                    Plotly.newPlot(                        \"bd0b25ae-db20-4a67-876d-1ada92e3ace9\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"subsample (DiscreteUniformDistribution): 0.02050943311844582<extra></extra>\",\"max_features (CategoricalDistribution): 0.10429730725016924<extra></extra>\",\"learning_rate (LogUniformDistribution): 0.21005707784836436<extra></extra>\",\"n_estimators (IntUniformDistribution): 0.30452557489325016<extra></extra>\",\"max_depth (IntUniformDistribution): 0.3606106068897704<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.02050943311844582\",\"0.10429730725016924\",\"0.21005707784836436\",\"0.30452557489325016\",\"0.3606106068897704\"],\"textposition\":\"outside\",\"texttemplate\":\"%{text:.2f}\",\"type\":\"bar\",\"x\":[0.02050943311844582,0.10429730725016924,0.21005707784836436,0.30452557489325016,0.3606106068897704],\"y\":[\"subsample\",\"max_features\",\"learning_rate\",\"n_estimators\",\"max_depth\"]}],                        {\"showlegend\":false,\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}}},                        {\"staticPlot\": true, \"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('bd0b25ae-db20-4a67-876d-1ada92e3ace9');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"markdown","source":"This plot is massively useful! It tells us several things, including:\n- `max_depth` and `learning_rate` are the most important\n- `subsample` and `max_features` are useless for minimizing the loss\n\nA plot like this comes in handy when tuning models with many hyperparameters. For example, you could take a test run of 40–50 trials and plot the parameter importances.\n\nDepending on the plot, you might decide to discard some less important parameters and give a larger search space for other ones, possibly reducing the search time and space.\n\nYou can check out [this page](https://optuna.readthedocs.io/en/stable/reference/visualization/index.html) of the documentation for more information on Optuna's supported plot types. ","metadata":{}},{"cell_type":"markdown","source":"# Summary","metadata":{}},{"cell_type":"markdown","source":"I think we can all agree that Optuna lived up to the whole hype I made in the introduction. It is awesome!\n\nThis kernel only gave you the basics you can do with Optuna. Actually, Optuna is capable of much more. Some of the critical topics we didn't cover today:\n- [Use cases of Optuna with other ML/DL frameworks](https://github.com/optuna/optuna-examples/)\n- [Choosing a pruning algorithm to immediately weed out unpromising trials](https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/003_efficient_optimization_algorithms.html#activating-pruners)\n- [Parallelization](https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html)\n\nand the coolest of all:\n- [Using SQLite or other databases (local or remote) to run massive-scale optimization with resume/pause capabilities](https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/001_rdb.html#sphx-glr-tutorial-20-recipes-001-rdb-py)\n\nDo check out the links to the relevant documentation pages. In the meantime, I will work on another kernel that shows how to use Optuna with XGBoost and choose a pruning algorithm. See you!","metadata":{}},{"cell_type":"markdown","source":"## You might also be interested...\n- [Automatic Hyperparameter Tuning with Sklearn GridSearchCV and RandomizedSearchCV](https://towardsdatascience.com/automatic-hyperparameter-tuning-with-sklearn-gridsearchcv-and-randomizedsearchcv-e94f53a518ee?source=your_stories_page-------------------------------------)\n- [11 Times Faster Hyperparameter Tuning with HalvingGridSearch](https://towardsdatascience.com/11-times-faster-hyperparameter-tuning-with-halvinggridsearch-232ed0160155?source=your_stories_page-------------------------------------)\n- [20 Burning XGBoost FAQs Answered to Use the Library Like a Pro](https://towardsdatascience.com/20-burning-xgboost-faqs-answered-to-use-the-library-like-a-pro-f8013b8df3e4?source=your_stories_page-------------------------------------)","metadata":{}}]}